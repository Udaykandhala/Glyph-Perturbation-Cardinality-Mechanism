{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fac56-5e53-49f0-b375-266f3a6ab172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMAGE to TEXT STEGANOGRAPHY (Glyph Perturbation Cardinality, GPC)\n",
    "\n",
    "This script extends the glyph perturbation cardinality framework to\n",
    "spatial visual data by embedding image content into rendered text glyphs.\n",
    "Rather than modifying image pixels directly, image intensities are first\n",
    "converted into bounded integer payloads compatible with the glyph-level\n",
    "perturbation channel.\n",
    "\n",
    "Each RGB image is resized to a canonical resolution and processed\n",
    "channel-wise. Pixel intensities in each channel are normalized from\n",
    "[0, 255] into integer values v ∈ [0, 26]. Each integer value is then\n",
    "embedded into a single text glyph by perturbing exactly v interior ink\n",
    "pixels within its rasterized representation.\n",
    "\n",
    "The raster embedding and decoding mechanisms are identical to the\n",
    "text-to-text case; only the payload formation differs.\n",
    "\n",
    "Decoding is performed by re-rasterizing the cover text, recovering\n",
    "perturbation counts per glyph, inverse-normalizing the integer payloads,\n",
    "and reconstructing approximate RGB image channels.\n",
    "\n",
    "This experiment demonstrates:\n",
    "- Deterministic and stable glyph-level embedding of spatial data\n",
    "- High-fidelity image reconstruction under aggressive low-cardinality\n",
    "  quantization\n",
    "- Preservation of glyph contours and visual text appearance\n",
    "- That rendered text can act as a covert carrier for image information\n",
    "  without introducing visible artifacts\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# IMPORTING LIBRARIES\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "# CONFIGURATION (MAIN PAPER SETTINGS)\n",
    "IMAGE_PATH = \"Image1.jpg\"   #Input Image\n",
    "OUT_DIR = \"image_to_text_result\"   # Output Directory\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Deterministic rendering parameters\n",
    "TILE_W, TILE_H = 40, 50\n",
    "FONT_SIZE = 36\n",
    "CANON_SIZE = (256, 256)  # image resolution\n",
    "\n",
    "# Payload constraints\n",
    "P_MAX = 26\n",
    "SEED = 42\n",
    "\n",
    "# Grayscale convention\n",
    "BG = 255\n",
    "INK = 0\n",
    "DELTA = 1\n",
    "\n",
    "# Cover Text\n",
    "COVER_TEXT = (\n",
    "    \"Once upon a misty autumn eve, a lone fox named Ember discovered an ancient silver key \"\n",
    "    \"glowing beneath crimson leaves in the whispering woods. \"\n",
    ") * 2500\n",
    "\n",
    "# ============================================================\n",
    "# COVER TEXT UTILIZATION REPORT (CLARIFIED)\n",
    "# ============================================================\n",
    "\n",
    "channels = 3  # R, G, B\n",
    "glyphs_per_channel = used_per_channel\n",
    "total_payload_glyphs = glyphs_per_channel * channels\n",
    "unused = total_cover_glyphs - glyphs_per_channel\n",
    "utilization_pct = (glyphs_per_channel / total_cover_glyphs) * 100.0\n",
    "\n",
    "print(\"\\n===== COVER TEXT UTILIZATION =====\")\n",
    "print(f\"Total alphabetic cover glyphs available : {total_cover_glyphs}\")\n",
    "print(f\"Glyphs required per channel             : {glyphs_per_channel}\")\n",
    "print(f\"Channels encoded                        : {channels}\")\n",
    "print(f\"Total payload glyphs (R+G+B)            : {total_payload_glyphs}\")\n",
    "print(f\"Unused cover glyphs                     : {unused}\")\n",
    "print(f\"Cover utilization (per channel)         : {utilization_pct:.2f}%\")\n",
    "print(\"Reuse model                             : SAME glyph positions reused per channel\")\n",
    "print(\"===================================\")\n",
    "\n",
    "with open(f\"{OUT_DIR}/cover_usage.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"IMAGE TO TEXT (GPC) - COVER TEXT UTILIZATION\\n\")\n",
    "    f.write(f\"Total alphabetic cover glyphs : {total_cover_glyphs}\\n\")\n",
    "    f.write(f\"Glyphs required per channel   : {glyphs_per_channel}\\n\")\n",
    "    f.write(f\"Channels encoded              : {channels}\\n\")\n",
    "    f.write(f\"Total payload glyphs          : {total_payload_glyphs}\\n\")\n",
    "    f.write(f\"Unused cover glyphs           : {unused}\\n\")\n",
    "    f.write(f\"Utilization per channel (%)   : {utilization_pct:.2f}\\n\")\n",
    "    f.write(\"Reuse model                   : SAME glyph positions reused per channel\\n\")\n",
    "\n",
    "\n",
    "# FONT LOADING (robust loading)\n",
    "def load_font(size: int):\n",
    "    for p in [\"arial.ttf\", \"DejaVuSansMono.ttf\"]:\n",
    "        try:\n",
    "            return ImageFont.truetype(p, size)\n",
    "        except:\n",
    "            pass\n",
    "    return ImageFont.load_default()\n",
    "\n",
    "FONT = load_font(FONT_SIZE)\n",
    "\n",
    "# METRICS (IMAGE DOMAIN)\n",
    "def mse(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    diff = a.astype(np.float64) - b.astype(np.float64)\n",
    "    return float(np.mean(diff * diff))\n",
    "\n",
    "def mae(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.mean(np.abs(a.astype(np.float64) - b.astype(np.float64))))\n",
    "\n",
    "def rmse(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.sqrt(mse(a, b)))\n",
    "\n",
    "def psnr(a: np.ndarray, b: np.ndarray, max_val: float = 255.0) -> float:\n",
    "    m = mse(a, b)\n",
    "    if m == 0:\n",
    "        return float(\"inf\")\n",
    "    return float(20.0 * np.log10(max_val / np.sqrt(m)))\n",
    "\n",
    "def snr_db(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Image SNR in dB: 10 log10( sum(signal^2) / sum(error^2) ).\"\"\"\n",
    "    a64 = a.astype(np.float64)\n",
    "    e64 = (a.astype(np.float64) - b.astype(np.float64))\n",
    "    num = np.sum(a64 * a64)\n",
    "    den = np.sum(e64 * e64) + 1e-12\n",
    "    return float(10.0 * np.log10(num / den))\n",
    "\n",
    "def ssim_rgb(a: np.ndarray, b: np.ndarray):\n",
    "    \"\"\"\n",
    "    SSIM computed per channel; returns (avg, (r,g,b)).\n",
    "    Note: skimage's ssim expects 2D arrays for each channel.\n",
    "    \"\"\"\n",
    "    sr = float(ssim(a[:, :, 0], b[:, :, 0], data_range=255))\n",
    "    sg = float(ssim(a[:, :, 1], b[:, :, 1], data_range=255))\n",
    "    sb = float(ssim(a[:, :, 2], b[:, :, 2], data_range=255))\n",
    "    return float((sr + sg + sb) / 3.0), (sr, sg, sb)\n",
    "\n",
    "\n",
    "# IMAGE to PAYLOAD\n",
    "def image_to_payload(path: str):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = img.resize(CANON_SIZE, Image.BILINEAR)\n",
    "    arr = np.asarray(img)\n",
    "\n",
    "    payload = {}\n",
    "    for i, ch in enumerate([\"R\", \"G\", \"B\"]):\n",
    "        payload[ch] = np.rint(arr[:, :, i] / 255.0 * P_MAX).astype(int).flatten()\n",
    "    return payload, arr\n",
    "\n",
    "\n",
    "# COVER TEXT\n",
    "def extract_cover_letters(text: str):\n",
    "    return [c for c in text.upper() if c.isalpha()]\n",
    "\n",
    "def cover_letters(text: str, n: int):\n",
    "    letters = extract_cover_letters(text)\n",
    "    if len(letters) < n:\n",
    "        raise ValueError(\n",
    "            f\"Cover text too short: need {n} alphabetic glyphs, have {len(letters)}.\"\n",
    "        )\n",
    "    return letters[:n], len(letters)\n",
    "\n",
    "\n",
    "# GLYPH RASTER\n",
    "def rasterize_glyph(ch: str) -> np.ndarray:\n",
    "    img = Image.new(\"L\", (TILE_W, TILE_H), BG)\n",
    "    d = ImageDraw.Draw(img)\n",
    "    bbox = d.textbbox((0, 0), ch, font=FONT)\n",
    "    w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "    d.text(((TILE_W - w) // 2, (TILE_H - h) // 2), ch, fill=INK, font=FONT)\n",
    "    return np.asarray(img, np.uint8)\n",
    "\n",
    "def encode_glyph(can: np.ndarray, v: int, rng: random.Random) -> np.ndarray:\n",
    "    enc = can.copy()\n",
    "    pts = list(zip(*np.where(can == INK)))\n",
    "    for r, c in rng.sample(pts, min(v, len(pts))):\n",
    "        enc[r, c] = INK + DELTA\n",
    "    return enc\n",
    "\n",
    "def decode_glyph(can: np.ndarray, enc: np.ndarray) -> int:\n",
    "    return int(((can == INK) & (enc == INK + DELTA)).sum())\n",
    "\n",
    "def arrange_tiles(tiles, per_row: int = 80) -> np.ndarray:\n",
    "    blank = np.full((TILE_H, TILE_W), BG, np.uint8)\n",
    "    rows = []\n",
    "    for i in range(0, len(tiles), per_row):\n",
    "        row = tiles[i:i + per_row]\n",
    "        if len(row) < per_row:\n",
    "            row += [blank] * (per_row - len(row))\n",
    "        rows.append(np.hstack(row))\n",
    "    return np.vstack(rows)\n",
    "\n",
    "\n",
    "# CHANNEL PIPELINE\n",
    "def encode_channel(vals: np.ndarray):\n",
    "    letters, total_cover_letters = cover_letters(COVER_TEXT, len(vals))\n",
    "    rng = random.Random(SEED)\n",
    "\n",
    "    can_tiles, enc_tiles = [], []\n",
    "    for ch, v in zip(letters, vals):\n",
    "        can = rasterize_glyph(ch)\n",
    "        enc = encode_glyph(can, int(v), rng)\n",
    "        can_tiles.append(can)\n",
    "        enc_tiles.append(enc)\n",
    "\n",
    "    return can_tiles, enc_tiles, total_cover_letters\n",
    "\n",
    "def decode_channel(can_tiles, enc_tiles) -> np.ndarray:\n",
    "    return np.array([decode_glyph(c, e) for c, e in zip(can_tiles, enc_tiles)], dtype=int)\n",
    "\n",
    "\n",
    "# MAIN PIPELINE\n",
    "payload, original = image_to_payload(IMAGE_PATH)\n",
    "decoded_channels = {}\n",
    "\n",
    "total_cover_glyphs = None\n",
    "used_per_channel = None\n",
    "\n",
    "for ch in [\"R\", \"G\", \"B\"]:\n",
    "    can_tiles, enc_tiles, cover_count = encode_channel(payload[ch])\n",
    "    dec_vals = decode_channel(can_tiles, enc_tiles)\n",
    "\n",
    "    # utilization bookkeeping (same for all channels)\n",
    "    if total_cover_glyphs is None:\n",
    "        total_cover_glyphs = cover_count\n",
    "    if used_per_channel is None:\n",
    "        used_per_channel = len(dec_vals)\n",
    "\n",
    "    # reconstruct decoded channel in 0..255 domain\n",
    "    decoded = (dec_vals.reshape(CANON_SIZE) / P_MAX * 255.0).astype(np.uint8)\n",
    "    decoded_channels[ch] = decoded\n",
    "\n",
    "    # save canonical / encoded rasters (tiled)\n",
    "    Image.fromarray(arrange_tiles(can_tiles)).save(f\"{OUT_DIR}/canonical_{ch}.png\")\n",
    "    Image.fromarray(arrange_tiles(enc_tiles)).save(f\"{OUT_DIR}/encoded_{ch}.png\")\n",
    "\n",
    "    # save difference (binary perturbation map)\n",
    "    diff_tiles = [\n",
    "        ((can == INK) & (enc == INK + DELTA)).astype(np.uint8)\n",
    "        for can, enc in zip(can_tiles, enc_tiles)\n",
    "    ]\n",
    "    diff_img = arrange_tiles(diff_tiles) * 255\n",
    "    Image.fromarray(diff_img).save(f\"{OUT_DIR}/difference_{ch}.png\")\n",
    "\n",
    "\n",
    "decoded_rgb = np.stack([decoded_channels[c] for c in [\"R\", \"G\", \"B\"]], axis=-1)\n",
    "\n",
    "Image.fromarray(original).save(f\"{OUT_DIR}/original.png\")\n",
    "Image.fromarray(decoded_rgb).save(f\"{OUT_DIR}/decoded.png\")\n",
    "\n",
    "# METRICS REPORT (IMAGE DOMAIN)\n",
    "M = mse(original, decoded_rgb)\n",
    "A = mae(original, decoded_rgb)\n",
    "R = rmse(original, decoded_rgb)\n",
    "P = psnr(original, decoded_rgb)\n",
    "SNR = snr_db(original, decoded_rgb)\n",
    "SS_avg, (SS_r, SS_g, SS_b) = ssim_rgb(original, decoded_rgb)\n",
    "\n",
    "with open(f\"{OUT_DIR}/metrics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"IMAGE → TEXT (GPC) METRICS (0–26)\\n\")\n",
    "    f.write(f\"Image: {IMAGE_PATH}\\n\")\n",
    "    f.write(f\"Resolution: {CANON_SIZE[0]}x{CANON_SIZE[1]}\\n\")\n",
    "    f.write(f\"P_MAX: {P_MAX}, DELTA: {DELTA}, SEED: {SEED}\\n\\n\")\n",
    "\n",
    "    f.write(f\"MSE  : {M}\\n\")\n",
    "    f.write(f\"MAE  : {A}\\n\")\n",
    "    f.write(f\"RMSE : {R}\\n\")\n",
    "    f.write(f\"PSNR : {P}\\n\")\n",
    "    f.write(f\"SNR  : {SNR} dB\\n\")\n",
    "    f.write(f\"SSIM avg: {SS_avg}\\n\")\n",
    "    f.write(f\"SSIM R  : {SS_r}\\n\")\n",
    "    f.write(f\"SSIM G  : {SS_g}\\n\")\n",
    "    f.write(f\"SSIM B  : {SS_b}\\n\")\n",
    "\n",
    "# COVER TEXT UTILIZATION REPORT\n",
    "unused = total_cover_glyphs - used_per_channel\n",
    "\n",
    "print(\"\\n===== COVER TEXT UTILIZATION =====\")\n",
    "print(f\"Total alphabetic cover glyphs available : {total_cover_glyphs}\")\n",
    "print(f\"Glyphs used for embedding (per channel) : {used_per_channel}\")\n",
    "print(f\"Unused cover glyphs                     : {unused}\")\n",
    "print(\"===================================\")\n",
    "\n",
    "with open(f\"{OUT_DIR}/cover_usage.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"COVER TEXT UTILIZATION\\n\")\n",
    "    f.write(f\"Total alphabetic cover glyphs : {total_cover_glyphs}\\n\")\n",
    "    f.write(f\"Used glyphs (per channel)     : {used_per_channel}\\n\")\n",
    "    f.write(f\"Unused glyphs                 : {unused}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n✓ Image → Text GPC completed successfully\")\n",
    "print(\"✓ Canonical, encoded, difference rasters saved per channel\")\n",
    "print(\"✓ Metrics saved to metrics.txt\")\n",
    "print(\"✓ Cover usage saved to cover_usage.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
